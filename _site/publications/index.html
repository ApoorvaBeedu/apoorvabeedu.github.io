<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Apoorva  Beedu


  | Publications

</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/publications/">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="http://localhost:4000/">
        <span class="font-weight-bold">Apoorva</span> 
        Beedu
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              Home
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
            <a class="nav-link" href="/publications/">
              Publications
              
              <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <div class="toggle-container">
            <a id="light-toggle">
              <i class="fas fa-moon"></i>
              <i class="fas fa-sun"></i>
            </a>
          </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>

    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
    <p class="post-description"></p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
    
  </div>

  <div id="beedu2021videopose" class="col-sm-8">
    
    <div class="title">VideoPose: Estimating 6D object pose from videos</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Beedu, Apoorva</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Ren, Zhile,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Agrawal, Varun,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Essa, Irfan
      
      
      
      
      
    </div>

    <div class="periodical">
      
      
      
      2021
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="/assets/pdf/VideoPose.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
      
      
      
      
      
      
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We introduce a simple yet effective algorithm that uses convolutional neural networks to directly estimate object poses from videos. Our approach leverages the temporal information from a video sequence, and is computationally efficient and robust to support robotic and AR domains. Our proposed network takes a pre-trained 2D object detector as input, and aggregates visual features through a recurrent neural network to make predictions at each frame. Experimental evaluation on the YCB-Video dataset show that our approach is on par with the state-of-the-art algorithms. Further, with a speed of 30 fps, it is also more efficient than the state-of-the-art, and therefore applicable to a variety of applications that require real-time object pose estimation.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
    
  </div>

  <div id="haresamudram2020masked" class="col-sm-8">
    
    <div class="title">Masked reconstruction based self-supervision for human activity recognition</div>
    <div class="author">
      
      
      
      
      

      
      
      
      
      Haresamudram, Harish,
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Beedu, Apoorva</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Agrawal, Varun,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Grady, Patrick L,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Essa, Irfan,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Hoffman, Judy,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Plötz, Thomas
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>In Proceedings of the 2020 International Symposium on Wearable Computers</em>
      
      
      
      2020
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="/assets/pdf/masked_reconstruction.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
      
      
      
      
      
      
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The ubiquitous availability of wearable sensing devices has rendered large scale collection of movement data a straightforward endeavor. Yet, annotation of these data remains a challenge and as such, publicly available datasets for human activity recognition (HAR) are typically limited in size as well as in variability, which constrains HAR model training and effectiveness. We introduce masked reconstruction as a viable self-supervised pre-training objective for human activity recognition and explore its effectiveness in comparison to state-of-the-art unsupervised learning techniques. In scenarios with small labeled datasets, the pre-training results in improvements over end-to-end learning on two of the four benchmark datasets. This is promising because the pre-training objective can be integrated “as is” into state-of-the-art recognition pipelines to effectively facilitate improved model robustness, and thus, ultimately, leading to better recognition performance.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li></ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
    
  </div>

  <div id="apoorva2015location" class="col-sm-8">
    
    <div class="title">Location based payload imaging</div>
    <div class="author">
      
      
      
      
      

      
      
      
      
      Apoorva, J,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Mohan, Brinda,
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Beedu, Apoorva</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Nayak, Mahendra M,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Rao, Divya,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Agrawal, VK
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>In 2015 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)</em>
      
      
      
      2015
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="/assets/pdf/location_based_payload_imaging.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
      
      
      
      
      
      
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>PISAT is a nano-satellite currently under development at PES University, Bangalore. It is an imaging satellite with the GOMSPACE Nanocam C1U as its main payload. It is three axis stabilized with active magnetic control system. Data reception and transmission is through S-band communication system. PES ground station has been commissioned exclusively for the purpose of communicating with PISAT. In the present configuration of PISAT, imaging can be carried out only during ground station visibility, which is for approximately 15 minutes. The dedicated ground station being located at Bangalore, the satellite can thus capture images only over Bangalore in this current mode. However, it is desirable that PISAT be able to carry out imaging at any commanded latitude and longitude. This paper presents a method to add this capability of imaging anywhere by including a provision to estimate the time required to reach the desired latitude and longitude using Location-Based Payload Imaging.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    © Copyright 2021 Apoorva  Beedu.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>.

    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  





</html>
